{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read and process groundwater data ILVO Field"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load essential Python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xlrd\n",
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "#from pandasql import sqldf\n",
    "import datetime\n",
    "import csv\n",
    "import pdb\n",
    "from tqdm.notebook import tqdm\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "from matplotlib.ticker import FuncFormatter\n",
    "def minor_formatter(x, ind):\n",
    "    # only format if we don't overlap with a major tick\n",
    "    if np.mod(x, 1) < .1:\n",
    "        return ''\n",
    "    return '{:.1f}'.format(np.mod(x, 1))\n",
    "def alternate_formatter(x, ind):\n",
    "    rm = np.mod(x, 1)\n",
    "    if np.abs(rm) < .1:\n",
    "        return '{:d}'.format(int(x))\n",
    "    return '{:.1f}'.format(rm)\n",
    "%matplotlib ipympl\n",
    "\n",
    "#!pip install traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Climate Data  (www.dacom.nl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'climday' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-a27c67a3de54>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;31m#s=clim.set_index('date_time',inplace=True)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;31m#climday=clim.groupby(clim.date.dt.floor('d')).sum().reset_index()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m \u001b[0mclimday\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[0mclimday\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'd'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0magg\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'precipitation'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'sum'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'air_temperature'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;34m'mean'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'climday' is not defined"
     ]
    }
   ],
   "source": [
    "%matplotlib ipympl\n",
    "#hourly data=dacom_weather_data, dailydata=dacom_weather_day\n",
    "path1 = os.getcwd()\n",
    "path = os.path.join(path1, 'data', 'raw_data')\n",
    "\n",
    "dacomdailyfile = os.path.join(path, 'dacom_weather_day.csv')\n",
    "dacomdaily=pd.read_csv(dacomdailyfile,sep=';',dayfirst=True)\n",
    "dacomdaily['Date']=pd.to_datetime(dacomdaily['Date'].str.replace('/', '-'), errors='coerce')\n",
    "dacomdaily=dacomdaily.set_index('Date')\n",
    "\n",
    "\n",
    "file = os.path.join(path, 'dacom_weather_data.csv')\n",
    "#climate data from  www.dacom.nl\n",
    "clim=pd.read_csv(file,sep=';')\n",
    "clim['date'] = pd.to_datetime(clim['date'], format = '%m/%d/%Y')\n",
    "#clim.date_time.dtype\n",
    "#s=clim.set_index('date_time',inplace=True)\n",
    "S#climday=clim.groupby(clim.date.dt.floor('d')).sum().reset_index()\n",
    "climday\n",
    "\n",
    "climday = clim.groupby(clim.date.dt.floor('d')).agg({'precipitation': ['sum'],'air_temperature': ['mean']})\n",
    "climday.columns  = ['_'.join(col) for col in climday.columns.values]\n",
    "climday                \n",
    "#climdaily=clim.resample('D', how='sum')#, 'air_temperature': np.mean,'rel_humidity': np.mean})\n",
    "\n",
    "#climdaily=clim.resample('1d', origin=clim.index.max().ceil('D'),closed='right', label='right').sum()\n",
    "#(climdaily)\n",
    "#print(clim.date_time.dtype)\n",
    "#climdaily.reset_index().plot(kind='scatter', x='date_time', y='precipitation')\n",
    "\n",
    "#climdaily.to_excel('saved_climfile2.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'climday' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-64f4adb487f3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#comparing daily and hourly data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#clim.groupby(clim.date.dt.floor('d')).sum().reset_index()\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclimday\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprecipitation_sum\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdacomdaily\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdacomdaily\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mPrec\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'climday' is not defined"
     ]
    }
   ],
   "source": [
    "%matplotlib ipympl\n",
    "#comparing daily and hourly data\n",
    "#clim.groupby(clim.date.dt.floor('d')).sum().reset_index()\n",
    "plt.plot(climday.precipitation_sum)\n",
    "plt.plot(dacomdaily.index,dacomdaily.Prec)\n",
    "\n",
    "#clim3 = clim2.loc[((clim2['precipitation'] == 0))] \n",
    "\n",
    "#ie=clim2['precipitation']> 0\n",
    "#clim3=clim2[ie]\n",
    "#print(clim3)\n",
    "#plt.scatter(clim2.index,clim2.precipitation)\n",
    "print(sum(climday.precipitation_sum),sum(dacomdaily.Prec))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dacomdaily"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datapath =  os.path.join(path1, 'data')\n",
    "baro_ind='AP825'\n",
    "xls_files = glob.glob(datapath + \"\\*.xlsx\") # change to csv \n",
    "#barometer felt down in pipe on   '2022-05-25 07:25:00'  \n",
    "#loop over the list of xls files\n",
    "ind = 0\n",
    "diver_names={}\n",
    "alldf={}\n",
    "for i,f in tqdm(enumerate(xls_files),total=len(xls_files)):\n",
    "    # read the csv file\n",
    "    df = pd.read_excel(f)\n",
    "    #print(df)\n",
    "    # remove double copied parts of the logged data from the raw data files\n",
    "    df=df.drop_duplicates()  \n",
    "    df=df.assign(Date=df.TimeStamp.dt.round('H'))\n",
    "    \n",
    "    df['Date']=pd.to_datetime(df['Date'],dayfirst=True)\n",
    "    df=df.loc[(df['TimeStamp'] > '2022-08-02 12:00:00')]\n",
    "    dfdaily=df.resample('D', on = 'Date').mean()\n",
    "\n",
    "    # merge all data in 1 dataframe\n",
    "    if baro_ind in f:\n",
    "        baro_data=df\n",
    "        baro_data=baro_data.loc[(baro_data['TimeStamp'] > '2022-08-02 12:00:00')]\n",
    "        #baro_data=baro_data.append.df# this tests for substrings\n",
    "    if ind == 0:\n",
    "        #First data frame loaded\n",
    "        GWdata = df\n",
    "        GWdata_daily = dfdaily\n",
    "    else:\n",
    "        # Paste the rest to this dataframe\n",
    "        GWdata = pd.concat([GWdata,df],axis=0).reset_index(drop=True)\n",
    "        GWdata_daily = pd.concat([GWdata_daily,df],axis=0).reset_index(drop=True)\n",
    "        alldf[i]=df\n",
    "        alldf[i]=alldf[i].loc[(alldf[i]['TimeStamp'] > '2022-08-02 12:00:00')]\n",
    "        GWdata\n",
    "    ind = ind + 1 \n",
    "#Remove empty columns from the dataframe    \n",
    "#GWdata.drop(labels=['Conductivity', 'WaterLevel','WaterLevelReference'], axis=1)\n",
    "#GWdata.loc[GWdata[\"SerialNumber\"]=='AP825'].reset_index()\n",
    "#baro_data.reset_index()\n",
    "\n",
    "print(GWdata)\n",
    "print(baro_data)\n",
    "#GWdata.to_excel('saved_file1.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read manually measured water dephts for inspection of the data    \n",
    "path_obs=os.path.join(path1, 'data','raw_data')\n",
    "file_obs = os.path.join(path_obs, 'manual_check_water_depth.xlsx')\n",
    "df_info = pd.read_excel(file_obs)\n",
    "df_info['Time']=pd.to_datetime(df_info['Time'],dayfirst=True)\n",
    "(df_info.Time)\n",
    "df_info2=df_info[df_info.Time.notnull()]\n",
    "df_info2=df_info2.reset_index(drop=True)\n",
    "df_info2.iloc[:,3] = (-100*df_info2.iloc[:,3]) \n",
    "df_info2.iloc[:,4] =-100*df_info2.iloc[:,4] \n",
    "groups = df_info2.groupby('SerialNumber')\n",
    "colors = {'AG083':'#ff7f0e','AP707': '#8c564b','CA186': '#d62728','AZ649': '#2ca02c', 'CA969':'#9467bd'}\n",
    "print(df_info2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processing steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset Processing explanation\t\t\t\t\t\t\n",
    "1. Collect total pressure (TP) from divers\t\t (cmH2O)\t\t\t\t\n",
    "2. Calculate water pressure (WP) = TP - AP\t\t (cmH2O)\t\t\n",
    "3. Calculate hydraulic gradient. Take the timestep \"t\" at which a manual measurement is realized and calculate the hydraulic head\t\t\t\t\t\t\n",
    "     - H(t) = TW-WD(t)\t\t\t\t\t\t\n",
    "     - H (t+1) = H(t)  + (WP (t+1) - WP (t))/100\t\t\t\t\t\t\n",
    "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "With :\t\t\t\t\t\t\t\t\t\t\t\n",
    "AP= Air Pressure (cmH20)\t\t\t\t\t\t\t\t\t\t\t\n",
    "H=Hydraulic Head (mTAW)\t\t\t\t\t\t\n",
    "TW=Top well Elevation (mTAW)\t\t\t\t\t\t\n",
    "WD=Water depth from the top well (m)\t\t\t\t\t\t\t\t\t\t\t\t\n",
    "\t\t\t\t\t\t\n",
    "| well   name | well   name | soil elevation(mTAW) | well height above the ground (m) | Top well (mTAW) | rope length (m)|\n",
    "|:-----------:|:-----------:|:--------------------:|:--------------------------------:|:---------------:|:------------|\n",
    "|  AG083  |   a   |         21,30        |                 0.56                |      21,86      |    |\n",
    "|   AP707   |   b   |        20,5        |               0.43               |      20.93      |      |\n",
    "|   CA186  |   c   |       19,7         |               0.63               |        20.33    |        |\n",
    "|   AZ649   |   d   |         20,9        |              0.68                |      21.58      |      |\n",
    "|   CA969  |  e  |         22,3        |                0.7               |      23.0     |       |\n",
    "|   AP689   |     |                 |                            |            |           |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wellinfo = { 'SerialNumber' : ['AG083','AP707','CA186','AZ649','CA969'], \n",
    "            'WellName' : {'a','b','c','d','e'},\n",
    "            'lgnds' : ['a','b','c','d','e'],\n",
    "            'soil_mTAW' : [21.30,20.5,19.7,20.9,22.3],\n",
    "            'well_height' : [0.56,0.43,0.63,0.68,0.70],\n",
    "            'top_well_cm' :[2186,2093,2033,2158,2300],\n",
    "            'RL' : [350,332,341,370,377],\n",
    "            'L1':[294,289,278,302,307],\n",
    "            'initials' : [158,165,147,225,0],\n",
    "            'measure_time':['2022-08-02 17:30:00','2022-08-02 17:00:00',\n",
    "                        '2022-08-02 15:00:00','2022-08-02 11:00:00',\n",
    "                        '2021-08-02 13:00:00'],\n",
    "           'long':[108855,108899,108929,108884,108814],\n",
    "           'lat':[185311,185293,185281,185274,185203]}\n",
    "alldata={}\n",
    "dov={}\n",
    "date1=datetime.date(2022,8,1)\n",
    "date2=datetime.date(2022,11,5)\n",
    "ftsz=16\n",
    "\n",
    "fig, ax= plt.subplots(figsize=(15,5))\n",
    "axb=ax.twinx()\n",
    "\n",
    "for f,i in enumerate(wellinfo['SerialNumber']):\n",
    "    ddd=GWdata.loc[GWdata[\"SerialNumber\"]==i].reset_index()\n",
    "    dataall=baro_data.merge(ddd[['TimeStamp','Pressure']], on='TimeStamp')\n",
    "    dataall.SerialNumber=i\n",
    "    dataall[dataall['Pressure_y'].notna()]\n",
    "    dataall = dataall[dataall['Pressure_x']<dataall['Pressure_y']]\n",
    "    dataall[\"WL\"]=(dataall['Pressure_y']-dataall['Pressure_x'])\n",
    "    dataall=dataall.reset_index()\n",
    "    dataall[\"GWL\"]=wellinfo['RL'][f]-wellinfo['top_well_cm'][f]-dataall[\"WL\"]\n",
    "    if wellinfo['SerialNumber'][f]=='CA186':\n",
    "        ax.plot(dataall.TimeStamp[840:],(dataall[\"GWL\"][840:]/100),colors[i])\n",
    "    else:\n",
    "        ax.plot(dataall.TimeStamp,(dataall[\"GWL\"]/100),colors[i])\n",
    "    ax.set_ylim([-20.5,-18])\n",
    "    alldata[i]=dataall\n",
    "    \n",
    "    #calulcate based on TAW\n",
    "    #\n",
    "    #\n",
    "    #\n",
    "    #create data for DOV ???\n",
    "    dov[i]=([[dataall[\"TimeStamp\"].dt.strftime('%Y-%m-%dT%H:%M:%S.000+01:00')],-dataall[\"GWL\"]/100])\n",
    "    #\n",
    "    #\n",
    "    #dov[i].to_csv(wellinfo['lgnds'][f]+'_DOV.csv', index=False,header=False) \n",
    "\n",
    "ax.scatter(df_info2.Time, df_info2.iloc[:,5], 75,c=df_info2['SerialNumber'].map(colors),alpha=.2, marker='o')\n",
    "ax.legend(wellinfo['lgnds'],loc='upper left', fontsize=ftsz)\n",
    "ax.set_ylabel('GWL[mTAW]', fontsize= ftsz)\n",
    "ax.tick_params(axis='x', which='both', labelsize=ftsz-2,rotation=60)\n",
    "ax.tick_params(axis='y', which='both', labelsize=ftsz)\n",
    "\n",
    "\n",
    "\n",
    "axb.bar(clim['date_time'],clim.precipitation)\n",
    "axb.set_ylim([0, 30])\n",
    "axb.invert_yaxis()\n",
    "axb.set_ylabel('Precipitation [mm]', fontsize= ftsz)\n",
    "axb.tick_params(axis='x', which='both', labelsize=ftsz)\n",
    "axb.tick_params(axis='y', which='both', labelsize=ftsz)\n",
    "\n",
    "axb.set_xlim([date1,date2])\n",
    "\n",
    "print(dataall)\n",
    " \n",
    "#calculate Gradients [H2-H1/(Distance)], H mtaw between each pair of piezometer like (a,b), (b,c), (c,d),(b,d),(a,d) \n",
    "#\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = os.getcwd()\n",
    "path = os.path.join(path1, 'data')\n",
    "file = os.path.join(path, 'PiezometerD.csv')\n",
    "PiezoD=pd.read_csv(file,sep=';',dayfirst=True)\n",
    "\n",
    "print(PiezoD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wellinfo = { 'SerialNumber' : ['AG083','AP707','CA186','AZ649','CA969'], \n",
    "            'WellName' : {'a','b','c','d','e'},\n",
    "            'lgnds' : ['a','b','c','d','e'],\n",
    "            'soil_mTAW' : [21.30,20.5,19.7,20.9,22.3],\n",
    "            'well_height' : [0.56,0.43,0.63,0.68,0.70],\n",
    "            'top_well_cm' :[2186,2093,2033,2158,2300],\n",
    "            'RL' : [350,332,341,370,377],\n",
    "            'L1':[294,289,278,302,307],\n",
    "            'initials' : [158,165,147,225,0],\n",
    "            'measure_time':['2022-08-02 17:30:00','2022-08-02 17:00:00',\n",
    "                        '2022-08-02 15:00:00','2022-08-02 11:00:00',\n",
    "                        '2021-08-02 13:00:00'],\n",
    "           'long':[108855,108899,108929,108884,108814],\n",
    "           'lat':[185311,185293,185281,185274,185203]}\n",
    "alldata={}\n",
    "dov={}\n",
    "date1=datetime.date(2022,8,1)\n",
    "date2=datetime.date(2022,11,5)\n",
    "ftsz=16\n",
    "\n",
    "fig, ax= plt.subplots(figsize=(15,5))\n",
    "axb=ax.twinx()\n",
    "\n",
    "\n",
    "\n",
    "for f,i in enumerate(wellinfo['SerialNumber']):\n",
    "    ddd=GWdata.loc[GWdata[\"SerialNumber\"]==i].reset_index()\n",
    "    dataall=baro_data.merge(ddd[['TimeStamp','Pressure']], on='TimeStamp')\n",
    "    dataall.SerialNumber=i\n",
    "    dataall[dataall['Pressure_y'].notna()]\n",
    "    dataall = dataall[dataall['Pressure_x']<dataall['Pressure_y']]\n",
    "    dataall[\"WL\"]=(dataall['Pressure_y']-dataall['Pressure_x'])\n",
    "    dataall=dataall.reset_index()\n",
    "    if wellinfo['SerialNumber'][f]=='AZ649':\n",
    "        dataall[\"GWL\"]=PiezoD['RL']-PiezoD['TopWell']-dataall[\"WL\"]\n",
    "    else:\n",
    "        dataall[\"GWL\"]=wellinfo['RL'][f]-wellinfo['top_well_cm'][f]-dataall[\"WL\"]\n",
    "    if wellinfo['SerialNumber'][f]=='CA186':\n",
    "        ax.plot(dataall.TimeStamp[840:],(dataall[\"GWL\"][840:]/100),colors[i])\n",
    "    else:\n",
    "        ax.plot(dataall.TimeStamp,(dataall[\"GWL\"]/100),colors[i])\n",
    "    ax.set_ylim([-20.5,-18])\n",
    "    alldata[i]=dataall\n",
    "    \n",
    "    #calulcate based on TAW\n",
    "    #\n",
    "    #\n",
    "    #\n",
    "    #create data for DOV ???\n",
    "    dov[i]=([[dataall[\"TimeStamp\"].dt.strftime('%Y-%m-%dT%H:%M:%S.000+01:00')],-dataall[\"GWL\"]/100])\n",
    "    #\n",
    "    #\n",
    "    #dov[i].to_csv(wellinfo['lgnds'][f]+'_DOV.csv', index=False,header=False) \n",
    "\n",
    "ax.scatter(df_info2.Time, df_info2.iloc[:,5], 75,c=df_info2['SerialNumber'].map(colors),alpha=.2, marker='o')\n",
    "ax.legend(wellinfo['lgnds'],loc='upper left', fontsize=ftsz)\n",
    "ax.set_ylabel('GWL[mTAW]', fontsize= ftsz)\n",
    "ax.tick_params(axis='x', which='both', labelsize=ftsz-2,rotation=60)\n",
    "ax.tick_params(axis='y', which='both', labelsize=ftsz)\n",
    "\n",
    "\n",
    "\n",
    "axb.bar(clim['date_time'],clim.precipitation)\n",
    "axb.set_ylim([0, 30])\n",
    "axb.invert_yaxis()\n",
    "axb.set_ylabel('Precipitation [mm]', fontsize= ftsz)\n",
    "axb.tick_params(axis='x', which='both', labelsize=ftsz)\n",
    "axb.tick_params(axis='y', which='both', labelsize=ftsz)\n",
    "\n",
    "axb.set_xlim([date1,date2])\n",
    "\n",
    "print(dataall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
